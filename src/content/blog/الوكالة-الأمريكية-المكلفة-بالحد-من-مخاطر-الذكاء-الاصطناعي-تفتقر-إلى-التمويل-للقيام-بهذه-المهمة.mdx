---
heroImage: /src/assets/images/960x0.webp
category: الذكاء الاصطناعي
description: >-
  إن خطة الرئيس الأمريكي جو بايدن لاحتواء مخاطر الذكاء الاصطناعي مهددة بالفعل
  بالخروج عن مسارها بسبب عدادات الكونجرس.
pubDate: 2023-12-23T23:00:00.000Z
tags:
  - الذكاء الاصطناعي
  - AI
title: >-
  الوكالة الأمريكية المكلفة بالحد من مخاطر الذكاء الاصطناعي تفتقر إلى التمويل
  للقيام بهذه المهمة
---

**إن خطة الرئيس الأمريكي جو بايدن لاحتواء مخاطر الذكاء الاصطناعي مهددة بالفعل بالخروج عن مسارها بسبب عدادات الكونجرس.**

ويدعو أمر تنفيذي صادر عن البيت الأبيض بشأن الذكاء الاصطناعي في أكتوبر/تشرين الأول الولايات المتحدة إلى تطوير معايير جديدة لاختبار تحمل أنظمة الذكاء الاصطناعي للكشف عن تحيزاتها وتهديداتها الخفية وميولها المارقة. لكن الوكالة المكلفة بوضع هذه المعايير، المعهد الوطني للمعايير والتكنولوجيا (NIST)، تفتقر إلى الميزانية اللازمة لإكمال هذا العمل بشكل مستقل بحلول الموعد النهائي في 26 يوليو 2024، وفقًا للعديد من الأشخاص المطلعين على العمل.

وفي حديثها في مؤتمر NeurIPS AI في نيو أورليانز الأسبوع الماضي، وصفت إلهام طباسي، المدير المساعد للتكنولوجيات الناشئة في NIST، هذا بأنه "موعد نهائي يكاد يكون مستحيلاً" بالنسبة للوكالة.

وقد أعرب بعض أعضاء الكونجرس عن قلقهم من أن المعهد الوطني للمعايير والتكنولوجيا سوف يضطر إلى الاعتماد بشكل كبير على خبرات الذكاء الاصطناعي من الشركات الخاصة التي، بسبب مشاريع الذكاء الاصطناعي الخاصة بها، لديها مصلحة خاصة في تشكيل المعايير.

لقد قامت حكومة الولايات المتحدة بالفعل باستغلال NIST للمساعدة في تنظيم الذكاء الاصطناعي. وفي يناير 2023، أصدرت الوكالة إطار عمل لإدارة مخاطر الذكاء الاصطناعي لتوجيه الأعمال والحكومة. ابتكرت NIST أيضًا طرقًا لقياس ثقة الجمهور في أدوات الذكاء الاصطناعي الجديدة. لكن الوكالة، التي تعمل على توحيد كل شيء بدءًا من المكونات الغذائية إلى المواد المشعة والساعات الذرية، لديها موارد ضئيلة مقارنة بموارد الشركات التي في طليعة الذكاء الاصطناعي. من المرجح أن كل من OpenAI وGoogle وMeta أنفقت ما يزيد عن 100 مليون دولار لتدريب نماذج اللغة القوية التي تدعم تطبيقات مثل ChatGPT وBard وLlama 2.

بلغت ميزانية المعهد الوطني للمعايير والتكنولوجيا لعام 2023 1.6 مليار دولار، وقد طلب البيت الأبيض زيادتها بنسبة 29% في عام 2024 للمبادرات التي لا تتعلق بشكل مباشر بالذكاء الاصطناعي. تقول عدة مصادر مطلعة على الوضع في NIST أن الميزانية الحالية للوكالة لن تمتد إلى اكتشاف اختبارات سلامة الذكاء الاصطناعي بمفردها.

في 16 ديسمبر/كانون الأول، وهو نفس اليوم الذي تحدث فيه تباسي في NeurIPS، وقع ستة من أعضاء الكونجرس على رسالة مفتوحة من الحزبين تثير المخاوف بشأن احتمال قيام NIST بتجنيد شركات خاصة مع القليل من الشفافية. وكتبوا: "لقد علمنا أن المعهد الوطني للمعايير والتكنولوجيا يعتزم تقديم منح أو جوائز لمنظمات خارجية لإجراء أبحاث خارج أسوارها". تحذر الرسالة من أنه لا يبدو أن هناك أي معلومات متاحة للجمهور حول كيفية تحديد هذه الجوائز.

تزعم رسالة المشرعين أيضًا أن NIST يتم التعجيل بها لتحديد المعايير على الرغم من أن البحث في اختبار أنظمة الذكاء الاصطناعي لا يزال في مرحلة مبكرة. ونتيجة لذلك، هناك "خلاف كبير" بين خبراء الذكاء الاصطناعي حول كيفية العمل على أو حتى قياس وتحديد قضايا السلامة المتعلقة بالتكنولوجيا، كما جاء في التقرير. تدعي الرسالة أن "الوضع الحالي لمجال أبحاث سلامة الذكاء الاصطناعي يخلق تحديات أمام NIST أثناء قيامها بدورها القيادي في هذه القضية".

وأكدت المتحدثة باسم NIST جنيفر هويرجو أن الوكالة تلقت الرسالة وقالت إنها "سترد عبر القنوات المناسبة".

يقوم NIST ببعض الخطوات التي من شأنها زيادة الشفافية، بما في ذلك إصدار طلب للحصول على معلومات في 19 ديسمبر، والتماس مدخلات من خبراء وشركات خارجية بشأن معايير التقييم ونماذج الذكاء الاصطناعي. ومن غير الواضح ما إذا كان هذا ردًا على الرسالة التي أرسلها أعضاء الكونجرس.

المخاوف التي أثارها المشرعون يتقاسمها بعض خبراء الذكاء الاصطناعي الذين أمضوا سنوات في تطوير طرق لاستكشاف أنظمة الذكاء الاصطناعي. يقول رومان شودري، عالم البيانات والرئيس التنفيذي لشركة Parity Consulting، والمتخصص في اختبار نماذج الذكاء الاصطناعي بحثًا عن التحيز والمشكلات الأخرى: "باعتبارها هيئة علمية غير حزبية، فإن NIST هي أفضل أمل للتغلب على الضجيج والتكهنات حول مخاطر الذكاء الاصطناعي". "لكن من أجل القيام بعملهم بشكل جيد، فإنهم يحتاجون إلى أكثر من مجرد التفويضات والتمنيات الطيبة".

يقول ياسين جيرنيت، قائد التعلم الآلي والمجتمع في شركة Hugging Face، وهي شركة تدعم مشاريع الذكاء الاصطناعي مفتوحة المصدر، إن شركات التكنولوجيا الكبرى لديها موارد أكثر بكثير من تلك التي تتمتع بها الوكالة التي تتولى دورًا رئيسيًا في تنفيذ خطة الذكاء الاصطناعي الطموحة للبيت الأبيض. يقول جيرنيت: "لقد قامت NIST بعمل رائع في المساعدة على إدارة مخاطر الذكاء الاصطناعي، لكن الضغط للتوصل إلى حلول فورية للمشاكل طويلة المدى يجعل مهمتهم صعبة للغاية". "لديهم موارد أقل بكثير من الشركات التي تقوم بتطوير معظم أنظمة الذكاء الاصطناعي المرئية."

تقول مارغريت ميتشل، كبيرة علماء الأخلاقيات في Hugging Face، إن السرية المتزايدة المحيطة بنماذج الذكاء الاصطناعي التجارية تجعل القياس أكثر صعوبة بالنسبة لمؤسسة مثل NIST. وتقول: "لا يمكننا تحسين ما لا نستطيع قياسه".

ويدعو الأمر التنفيذي للبيت الأبيض NIST إلى أداء العديد من المهام، بما في ذلك إنشاء معهد جديد لسلامة الذكاء الاصطناعي لدعم تطوير الذكاء الاصطناعي الآمن. وفي إبريل/نيسان، تم الإعلان عن تشكيل فريق عمل بريطاني يركز على سلامة الذكاء الاصطناعي. وسوف تتلقى 126 مليون دولار في التمويل الأولي.

أعطى الأمر التنفيذي NIST موعدًا نهائيًا صارمًا للتوصل إلى، من بين أمور أخرى، مبادئ توجيهية لتقييم نماذج الذكاء الاصطناعي، ومبادئ نماذج "الفريق الأحمر" (اختبار الخصومة)، ووضع خطة لإقناع الدول المتحالفة مع الولايات المتحدة بالموافقة على معايير NIST. والتوصل إلى خطة "لتطوير المعايير الفنية العالمية المسؤولة لتطوير الذكاء الاصطناعي".

على الرغم من أنه ليس من الواضح كيف تتعامل NIST مع شركات التكنولوجيا الكبرى، إلا أن المناقشات حول إطار إدارة المخاطر في NIST، والتي جرت قبل الإعلان عن الأمر التنفيذي، شملت شركة Microsoft؛ Anthropic، وهي شركة ناشئة أنشأها موظفون سابقون في OpenAI تعمل على بناء نماذج ذكاء اصطناعي متطورة؛ الشراكة في مجال الذكاء الاصطناعي، والتي تمثل شركات التكنولوجيا الكبرى؛ ومعهد مستقبل الحياة، وهو منظمة غير ربحية مخصصة للمخاطر الوجودية، من بين أمور أخرى.

يقول تشودري: "باعتباري عالمًا اجتماعيًا كميًا، فأنا أحب وأكره على حدٍ سواء إدراك الناس أن القوة تكمن في القياس".

sources :

\
 -[https://arstechnica.com/ai/2023/12/us-agency-tasked-with-curbing-risks-of-ai-lacks-funding-to-do-the-job/](https://arstechnica.com/ai/2023/12/us-agency-tasked-with-curbing-risks-of-ai-lacks-funding-to-do-the-job/)

-[https://www.wired.com/](https://www.wired.com/)
